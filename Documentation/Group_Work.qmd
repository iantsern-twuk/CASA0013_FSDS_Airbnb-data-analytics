---
bibliography: bio.bib
csl: harvard-cite-them-right.csl
title: CASA0013_FSDS_Airbnb_living la vida code-a
execute:
  echo: false
  freeze: true
format:
  html:
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    mainfont: Times
    sansfont: Times
    monofont: Times
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.16.4
  kernelspec:
    display_name: Python (base)
    language: python
    name: base
---

```{python}
#| echo: false
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns 
import geopandas as gpd
from shapely.geometry import Point
```

```{python}
import requests

def download_bib_file(url, output_path):
    if not os.path.exists(output_path):
        try:
            response = requests.get(url)
            response.raise_for_status()
            with open(output_path, 'w', encoding='utf-8') as file:
                file.write(response.text)
        except requests.exceptions.RequestException as e:
            print(f"Failed to render document: {e}")

download_bib_file("https://raw.githubusercontent.com/iantsern-twuk/CASA0013_FSDS_Airbnb-data-analytics/refs/heads/main/Documentation/bio.bib", "bio.bib")

download_bib_file("https://raw.githubusercontent.com/iantsern-twuk/CASA0013_FSDS_Airbnb-data-analytics/refs/heads/main/Documentation/harvard-cite-them-right.csl", "harvard-cite-them-right.csl")
```

```{python}
#| echo: false
host = 'https://orca.casa.ucl.ac.uk'
path = '~jreades/data'
file = '20240614-London-listings.parquet'

if os.path.exists(file):
  df = pd.read_parquet(file)
else: 
  df = pd.read_parquet(f'{host}/{path}/{file}')
  df.to_parquet(file)
```

## 1. Who collected the InsideAirbnb data?

::: {.duedate}

( 2 points; Answer due Week 7 )

:::

Prior to 2015, the InsideAirbnb (IA) data (going back to 2013) was collected by Tom Slee. From early 2015, the IA data was (and continues to be) collected by founder Murray Cox, an Australian community and data activist, together with a team of collaborators and advisors comprising artists, activists, researchers, and data scientists [@insideairbnb].

## 2. Why did they collect the InsideAirbnb data?

::: {.duedate}

( 4 points; Answer due Week 7 )

IA data seeks to challenge official data from Airbnb, which may be misrepresentative of its operations and impact [@slee_2016]. It offers an alternative perspective to Airbnb’s (limited) publicly available data by purposefully representing it through datasets and visualisations, with the not-for-profit goal of helping cities and communities to make informed decisions concerning Airbnb’s operations [@insideairbnb]. In doing so, IA increases data accessibility on Airbnb’s impacts on residential neighbourhoods worldwide, especially with regard to quantifying the ramifications of short-term lets [@wang_2024] on local communities.  

:::

```{python}
#| output: asis
print(f"One of way to embed output in the text looks like this: after cleaning, we were left with {df.shape[0]:,} rows of data.")
```

This way is also supposed to work (`{python} f"{df.shape[0]:,}" `) but I've found it less reliable.

```{python}
ax = df.host_listings_count.plot.hist(bins=50);
ax.set_xlim([0,500]);
```

## 3. How did they collect it?

::: {.duedate}
( 5 points; Answer due Week 8 )
:::

The IA data is collected through a process known as web-scraping, in which automated software repeatedly visits the Airbnb website and extracts publicly-available data from each listing, such as description, location, and room or property type [@prentice_2023]). The Python code used to scrape the data is available to the public on Github but has not been updated since 2019 [@alsudais_2021], meaning it is not possible to know exactly how the data are processed. However, IA does not merely scrape website data, but also processes these and augments them with assumptions about their nature [@insideairbnb]. These approaches will be discussed further below.



## 4. How does the method of collection (Q3) impact the completeness and/or accuracy of the InsideAirbnb data? How well does it represent the process it seeks to study, and what wider issues does this raise?

::: {.duedate}
( 11 points; Answer due Week 9 )
:::

As a scrape of Airbnb's website rather than the raw data themselves, the final IA datasets have potential biases and quality issues that should be taken into account by analysts and legislators using them to inform policy. Web-scraping only extracts publicly-available information on Airbnb’s website at the time the script is run: this means it cannot capture deleted listings or exact listing locations, as Airbnb anonymises these for privacy reasons [@prentice_2023]. In addition, Airbnb’s website does not differentiate between when listings are booked or blocked by their host [@crommelin_2018], meaning IA has to use review counts to roughly estimate occupancy rates. However, the process of scraping and processing by IA itself also introduces uncertainty. The web scrapes’ reservation query settings affect the data retrieved, meaning listings may be undercounted if they do not match the search’s parameters [@prentice_2023]. Furthermore, @alsudais_2021 found inaccuracies in the way IA had joined reviews and listing IDs.

Moreover, it is important to remember that Airbnb’s raw data is not necessarily accurate in the first place. Some listings may be fake, duplicates, or inactive [@adamiak_2022]. Finally, the IA data cannot capture short-term letting (STL) transactions through other platforms [@prentice_2023]. This raises the question of whether IA data alone can provide a holistic understanding of the STL market.


## 5. What ethical considerations does the use of the InsideAirbnb data raise? 

::: {.duedate}
( 18 points; Answer due {{< var assess.group-date >}} )
:::

The use of InsideAirbnb data raises a few ethical concerns due to the collection of the data through web scraping. Using an ethics framework developed by @krotov_2020 in their paper, the ethical concerns of web scraping Airbnb’s data can be categorised into infringement of individual and organisational privacy, rights of research subjects, data quality and discrimination. These categories are very applicable and in the case of IA, researchers should always be aware of identifying possible harm to individuals, organisations and enact precautionary measures to avoid these harms. 

Infringement of individual privacy and rights to research subjects are perhaps some of the most significant ethical concerns while using the IA dataset. Since web scraping involves extracting all possible data from a website before parsing and classifying them, these data may unintentionally infringe on users’ privacy as all web activities of individuals can be extracted, revealed and may be a means of personal identification in the future [@zook_2017]. The IA dataset covers users reviews with their first name, duration of stay, neighbourhood, and comments recorded. Although full names and exact locations are anonymised by Airbnb, details of user reviews may reveal more about their daily lives and can risk being re-identified with generative models [@rocher_2019]. Even if personal privacy is not harmed, users may not have given permission to researchers for the use of their data, infringing on rights of research subjects. This requires additional steps to protect anonymity of subjects by deleting identifiable information or detaching unique keys from the dataset [@kohlmayer_2019]. 

Airbnb’s privacy may also be compromised through web scraping since their listing data embedded were not meant to be revealed entirely to the public. This may lead to confidential operations of the company being leaked including market share, intended audiences and other trade secrets which can be maliciously used by competitors. For example, Uber was accused of using web scraping to conduct surveillance on its drivers and its competitors [@rosenblatt_2017].

## 6. With reference to the InsideAirbnb data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and the types of properties that they list suggest about the nature of Airbnb lettings in London? 

::: {.duedate}
( 15 points; Answer due {{< var assess.group-date >}} )
:::

__Room types__
Firstly, analysing the categories of Airbnb listing types reveals that the nature of room types available has changed over time. Looking at room type data from 2021 to 2024, we identified a rise in the proportion of listings that were entire homes (as opposed to single-room listings) from around 55% of total listings in 2021 to 64% in 2024. This suggests an overall shift in Airbnb activity: that there is increasing demand from tenants to rent entire-home Airbnbs, and that more hosts are listing entire homes to meet that demand, deviating from Airbnb’s claims to a “sharing economy” (Minton, 2023). Subsequently, an exploration of where in London this change is occurring most significantly reveals that entire-home listings remain predominant in central London but have steadily expanded outwards over the years. 

< Figure: Map showing density of entire-home listings MSOA , 2021 vs 2022 vs 2023 vs 2024 >

__Multiple-listing hosts__
Equally noteworthy is an analysis of multiple-listing hosts (hosts with more than 1 room/home listed). As IA notes, multiple listings are associated with commercial hosts (Inside Airbnb, 2024), who often escape housing and land-use policies and taxation applicable to traditional landlords (Wachsmuth & Weisler, 2018) and thus warrant greater scrutiny. Our analysis of the proportions of hosts possessing single (=1) and multiple properties (>=2) revealed that the percentage of multiple-listing hosts increased from 44.6% of total Airbnb listings in 2021 to 52.2% in 2024, indicating that the proportion of multiple-listing hosts is growing to occupy more of the listings market. The bar chart below visualising the change in number of listings owned by multiple- and single-listing hosts over the past 4 years confirms a steady growth in the presence of multiple-listing hosts.

```{python}
df_listings_2024 = pd.read_csv('data/raw/2023_listings.csv.gz', compression='gzip', low_memory=False) #compression='gzip' is to unzip the file
df_listings_2021 = pd.read_csv('data/raw/2021_listings.csv.gz', compression='gzip', low_memory=False)
df_listings_2022 = pd.read_csv('data/raw/2022_listings.csv.gz', compression='gzip', low_memory=False)
df_listings_2023 = pd.read_csv('data/raw/2023_listings.csv.gz', compression='gzip', low_memory=False)
df_msoa_map = gpd.read_file('data/shapefiles/MSOA_2011_London_gen_MHW.shp')

print(f"Data frame listings_2024 is {df_listings_2024.shape[0]:,} x {df_listings_2024.shape[1]}")
print(f"Data frame listings_2021 is {df_listings_2021.shape[0]:,} x {df_listings_2021.shape[1]}")
print(f"Data frame listings_2022 is {df_listings_2022.shape[0]:,} x {df_listings_2022.shape[1]}")
print(f"Data frame listings_2023 is {df_listings_2023.shape[0]:,} x {df_listings_2023.shape[1]}")
print(f"Data frame msoa_map is {df_msoa_map.shape[0]:,} x {df_msoa_map.shape[1]}")
```

```{python}
#add a new column called year to each dataframe
df_listings_2024['year'] = 2024
df_listings_2021['year'] = 2021
df_listings_2022['year'] = 2022
df_listings_2023['year'] = 2023

df_listings_combined = pd.concat([df_listings_2024, df_listings_2021, df_listings_2022, df_listings_2023], axis=0, ignore_index=True)   
print(f"Combined data frame is {df_listings_combined.shape[0]:,} x {df_listings_combined.shape[1]}")

#select the column I want to use
columns_to_use = ['id', 'listing_url', 'name', 'host_id', 'host_name', 'host_listings_count', 'host_total_listings_count', 'latitude', 'longitude', 'property_type', 'room_type', 'price', 'number_of_reviews','review_scores_rating', 'year']
df_listings_combined = df_listings_combined[columns_to_use]
print(f"Combined data frame is {df_listings_combined.shape[0]:,} x {df_listings_combined.shape[1]}")
#how many unigue id and host id
print(f"Number of unique id is {df_listings_combined['id'].nunique():,}")
print(f"Number of unique host id is {df_listings_combined['host_id'].nunique():,}")
```

```{python}
df_host_listings_count = df_listings_combined.groupby(['host_id', 'year'])['id'].nunique().reset_index()
df_host_listings_count.columns = ['host_id', 'year', 'host_listings_count']
df_host_listings_count

#count the category of host_listings_count
bins = [0, 2, float('inf')] #catogrize host_listings_count into <=1 and >2
labels = ['Single Property hosts', 'Multiple Properties hosts']
df_host_listings_count['category'] = pd.cut(df_host_listings_count['host_listings_count'], bins=bins, labels=labels, right=False)
df_host_listings_count
```

```{python}
#merge the df_listings_combined and df_host_listings_count
df_new_listings_combined = df_listings_combined.merge(df_host_listings_count, on=['host_id', 'year'], how='left') 
df_new_listings_combined = df_new_listings_combined.rename(columns={'host_listings_count_y': 'new_host_listings_count'})
df_new_listings_combined #make the latitude and longitude to geo dara frame point and create the new column called geometry_point

points = [Point(xy) for xy in zip(df_new_listings_combined['longitude'], df_new_listings_combined['latitude'])]
gdf_new_listings_combined = gpd.GeoDataFrame(df_new_listings_combined, geometry = points)
gdf_new_listings_combined.crs = "EPSG:4326"
gdf_new_listings_combined = gdf_new_listings_combined.rename(columns={'geometry': 'geometry_point'})
gdf_new_listings_combined.head()
```

```{python}
multiple_properties_ids = df_new_listings_combined[df_new_listings_combined['category'] == 'Multiple Properties hosts'].groupby('year')['id'].nunique()
single_property_ids = df_new_listings_combined[df_new_listings_combined['category'] == 'Single Property hosts'].groupby('year')['id'].nunique()
percentage_multiple_properties_ids = multiple_properties_ids / (multiple_properties_ids + single_property_ids)

sns.set(style="white") #like darkgrid, whitegrid, dark, white, ticks
fig, ax1 = plt.subplots(figsize=(10, 6))
bar_width = 0.35

index = np.arange(len(multiple_properties_ids))

# bar chart
ax1.bar(multiple_properties_ids.index, multiple_properties_ids,width=bar_width, color='#ff5c00', label='Count of listings by multiple-property hosts')
ax1.bar(single_property_ids.index + bar_width, single_property_ids,width=bar_width, color='#0061ff', label='Count of listings by single-property hosts')
ax1.set_xlabel('Year')
ax1.set_ylabel('Count of listings', color='black')
ax1.tick_params(axis='y', labelcolor='black')
ax1.set_xticks(multiple_properties_ids.index)  # year scale

# add legend
fig.legend(loc='upper left', bbox_to_anchor=(0.13, 0.88))
plt.grid(color='gray', linestyle='--', linewidth=0.5)
plt.title("Single- and Multi-property Hosts' Listings from 2021 to 2024")
plt.grid(True)
plt.show()

print(percentage_multiple_properties_ids)
```

< Figure 2 : Single- and Multi-property Hosts' Listings from 2021 to 2024 >

These trends in room and host types point towards the increasing commercialisation of Airbnb lets. More than bona fide home sharing, Airbnb appears to be a platform for commercial profit at the expense of local communities (Quattrone et al., 2016).


## 7. Drawing on your previous answers, and supporting your response with evidence (*e.g.* figures, maps, EDA/ESDA, and simple statistical analysis/models drawing on experience from, e.g., CASA0007), how *could* the InsideAirbnb data set be used to inform the regulation of Short-Term Lets (STL) in London? 

::: {.duedate}
( 45 points; Answer due {{< var assess.group-date >}} )
:::


## Sustainable Authorship Tools

Using the Terminal in Docker, you compile the Quarto report using `quarto render <group_submission_file>.qmd`.

Your QMD file should automatically download your BibTeX and CLS files and any other required files. If this is done right after library loading then the entire report should output successfully.

Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style="font-family:Sans-Serif;">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). 

## References
