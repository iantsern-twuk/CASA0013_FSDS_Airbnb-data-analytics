{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ef6345-a6ff-40b9-8e7a-8e592a9a08fe",
   "metadata": {},
   "source": [
    "# Testing the Efficacy of Airbnb's 90 Day Limit on Entire Home Listings\n",
    "\n",
    "**Research Question:** Did the imposition of the 90 day limit reduce the growth rate in proportion of entire home listings over 90 days in comparison to single rooms?\n",
    "\n",
    "**H0:** there is no difference in the change in proportion of entire home listings exceeding 90 days compared to single room listings after the imposition of the 90-day limit.\n",
    "\n",
    "**HA:** there is a difference in the change in proportion of entire home listings exceeding 90 days compared to single room listings after the imposition of the 90-day limit.\n",
    "\n",
    "The policy was introduced in Jan 2017, so I will test for differences in proportions between 2016 and 2017. There is, however, a possibility of a time lag, which means different years may yield different results.\n",
    "\n",
    "As this notebook aims to be reproducible and we are getting close to submission time, I'm not going to keep record of any QAing/data exploration - I'll only keep things which I think might make it into the final document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "77e66426-08d4-4667-b564-2e0d38023daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/Documentation\n"
     ]
    }
   ],
   "source": [
    "#Loading packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import duckdb as db\n",
    "import statsmodels.api as sm\n",
    "from requests import get\n",
    "from urllib.parse import urlparse\n",
    "from functools import wraps\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import ttest_rel\n",
    "import statsmodels.formula.api as smf\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffd3b6-0b54-4dd1-a66b-441c7fd0def7",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980893d-a3b5-41a1-a80f-6bd6408d5378",
   "metadata": {},
   "source": [
    "### 1.1 Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0cd06c34-7769-4a60-bf20-3ac756bad3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Documentation/data/raw/20240614-London-reviews.csv.gz found locally!\n"
     ]
    }
   ],
   "source": [
    "#Our Github has run out of storage so we cannot upload the data here\n",
    "#Instead I will use Jon's code to download the June 2024 reviews from his website and save it locally\n",
    "\n",
    "url  = 'https://orca.casa.ucl.ac.uk/~jreades/data/20240614-London-reviews.csv.gz'\n",
    "\n",
    "def check_cache(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(src, dst, min_size=100):\n",
    "        url = urlparse(src) # We assume that this is some kind of valid URL \n",
    "        fn  = os.path.split(url.path)[-1] # Extract the filename\n",
    "        dsn = os.path.join(dst,fn) #Â Destination filename\n",
    "        if os.path.isfile(dsn) and os.path.getsize(dsn) > min_size:\n",
    "            print(f\"+ {dsn} found locally!\")\n",
    "            return(dsn)\n",
    "        else:\n",
    "            print(f\"+ {dsn} not found, downloading!\")\n",
    "            return(f(src, dsn))\n",
    "    return wrapper\n",
    "\n",
    "@check_cache\n",
    "def cache_data(src:str, dst:str) -> str:\n",
    "    \"\"\"Downloads a remote file.\n",
    "    \n",
    "    The function sits between the 'read' step of a pandas or geopandas\n",
    "    data frame and downloading the file from a remote location. The idea\n",
    "    is that it will save it locally so that you don't need to remember to\n",
    "    do so yourself. Subsequent re-reads of the file will return instantly\n",
    "    rather than downloading the entire file for a second or n-th itme.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        The remote *source* for the file, any valid URL should work.\n",
    "    dst : str\n",
    "        The *destination* location to save the downloaded file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string representing the local location of the file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the path back into a list (without)\n",
    "    # the filename -- we need to check that directories\n",
    "    # exist first.\n",
    "    path = os.path.split(dst)[0]\n",
    "    print(f\"Path: {path}\")\n",
    "      \n",
    "    # Create any missing directories in dest(ination) path\n",
    "    # -- os.path.join is the reverse of split (as you saw above)\n",
    "    # but it doesn't work with lists... so I had to google how\n",
    "    # to use the 'splat' operator! os.makedirs creates missing\n",
    "    # directories in a path automatically.\n",
    "    if path != '':\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "    # Download and write the file\n",
    "    with open(dst, \"wb\") as file:\n",
    "        response = get(src)\n",
    "        file.write(response.content)\n",
    "        \n",
    "    print(' + Done downloading...')\n",
    "\n",
    "    return dst\n",
    "\n",
    "ddir = os.path.join('Documentation','data', 'raw') # destination directory\n",
    "path  = cache_data(url, ddir)\n",
    "reviews = pd.read_csv(path, compression='gzip')\n",
    "listings = pd.read_csv(\"data/raw/listings.csv.gz\")\n",
    "listings = listings[[\"id\", \"host_id\", \"room_type\", \"minimum_nights\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "21f51926-6d0d-4bdd-9133-48abad1c0fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest review date: 2024-06-17 00:00:00.\n",
      "This means the cutoff date for reviews is: 2022-06-17 00:00:00.\n"
     ]
    }
   ],
   "source": [
    "#Changing date data type\n",
    "reviews[\"date\"] = pd.to_datetime(reviews[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "#Splitting dates for last 24 months\n",
    "print(f\"Latest review date: {reviews.date.max()}.\")\n",
    "max_date = reviews.date.max()\n",
    "cutoff_2023 = max_date.replace(year=max_date.year - 1)\n",
    "cutoff_date = max_date.replace(year=max_date.year - 2)\n",
    "print(f\"This means the cutoff date for reviews is: {cutoff_date}.\")\n",
    "\n",
    "#Filter for only reviews from the last 24 months\n",
    "#Update: changing this to include all reviews from 2022 onwards (if we are doing 2022/2023 rather than 12 month series)\n",
    "reviews = reviews[reviews[\"date\"] >= '01-01-2022']\n",
    "min_date = reviews.date.min()- dt.timedelta(days=1)\n",
    "\n",
    "#Add column with year data (ChatGPT helped)\n",
    "reviews[\"year_category\"] = pd.cut(reviews[\"date\"],\n",
    "                        bins=[min_date, cutoff_date, cutoff_2023, max_date],\n",
    "                        labels=[\"Pre-Cutoff\", \"2022_2023\", \"2023_2024\"],\n",
    "                        right=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4a78d-419d-4c9d-9b37-308ce9fbd38d",
   "metadata": {},
   "source": [
    "### 1.3 Join Tables and Calculate Occupancy Metric\n",
    "\n",
    "Using Wang et al. (2024) occupancy estimation:\n",
    "1. Count reviews per listing per year\n",
    "2. Divide by 0.5 (assume that 1 in 2 stays results in a review)\n",
    "3. Join to the listings dataset\n",
    "4. Estimate stay length: either 3 days or minimum nights, whichever is larger\n",
    "5. Multiply this by review rate\n",
    "6. Cap at 21 nights per month (252) - *although technically 2016 was a leap year*\n",
    "\n",
    "Finally, work out whether a listing had estimated over 90 nights or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "71848425-259f-4ca1-be43-d118f3b3e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def over90proportions(reviews,listings,year_columns):\n",
    "    #Step 1: count reviews per listing per year\n",
    "    reviews_annual = reviews.groupby(['listing_id', 'year_category']).size().unstack(fill_value=0)\n",
    "    reviews_annual = reviews_annual.reset_index()\n",
    "    reviews_annual.columns.name = None\n",
    "    \n",
    "    #Step 2: divide each year by 0.5 (assume that 1 in 2 stays results in a review)\n",
    "    for year in year_columns:\n",
    "        reviews_annual[f'{year}_adjusted'] = reviews_annual[year] / 0.5\n",
    "        \n",
    "    #Step 3: join to the listings dataset\n",
    "    reviews_annual = reviews_annual.merge(listings, how='left', left_on='listing_id', right_on='id').drop(columns=['id'])\n",
    "\n",
    "    reviews_annual.dropna(subset=['room_type'], inplace=True)\n",
    "\n",
    "    #Step 4: calculating estimated nights column: greater of either 3 or minimum nights\n",
    "    reviews_annual['estimated_stay'] = np.maximum(3, reviews_annual.minimum_nights)\n",
    "\n",
    "    #Step 5: estimate occupied nights for each year by multiplying the adjusted review rate by the estimated stay duration\n",
    "    #n.b. this assumes that the minimum nights has not changed over time\n",
    "    #Step 6: cap at 21 days per month (not changing 2016 leap year as 1/365 = 0.002...)\n",
    "    \n",
    "    cap_nights = 12 * 21  # max 21 days per month\n",
    "    for year in year_columns:\n",
    "        reviews_annual[f'est_nights_{year}'] = reviews_annual[f'{year}_adjusted'] * reviews_annual.estimated_stay\n",
    "        reviews_annual[f'est_nights_{year}_capped'] = np.minimum(cap_nights, reviews_annual[f'est_nights_{year}'])\n",
    "\n",
    "    return reviews_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ddcae0fa-779a-4427-9edc-cc4d0811c967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13149/1669582155.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  reviews_annual = reviews.groupby(['listing_id', 'year_category']).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "reviews_annual = over90proportions(reviews,listings,['2022_2023','2023_2024'])\n",
    "\n",
    "reviews_annual.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591ad806-c0e9-441a-bd45-6ad856a2a755",
   "metadata": {},
   "source": [
    "### 1.2 Listing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "af0f4a69-2218-4c2d-bc2f-b4a677491868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>room_type</th>\n",
       "      <th>over90_2324</th>\n",
       "      <th>total_2324</th>\n",
       "      <th>over90_2223</th>\n",
       "      <th>total_2223</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>5032.0</td>\n",
       "      <td>14090.0</td>\n",
       "      <td>4257.0</td>\n",
       "      <td>10002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entire Home</td>\n",
       "      <td>6874.0</td>\n",
       "      <td>28244.0</td>\n",
       "      <td>4814.0</td>\n",
       "      <td>17391.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     room_type  over90_2324  total_2324  over90_2223  total_2223\n",
       "0        Other       5032.0     14090.0       4257.0     10002.0\n",
       "1  Entire Home       6874.0     28244.0       4814.0     17391.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating final table: whether a listing had True or False for over 90 days, and aggregated by room type\n",
    "#Only looking at room type for now connected to research question, but I have the host column in there to check for superhosts if necessary\n",
    "\n",
    "#Getting number of over 90s and totals for each category, as this is what the statistical test requires\n",
    "\n",
    "#ChatGPT suggested taking a dynamic approach which integrates the year variable into the query and iterate over it\n",
    "#But this felt a bit dishonest as it's not something I would have written myself\n",
    "#So please excuse the slightly unwiedly query - it's not the most scalable but it is legible and it was written entirely by me!\n",
    "\n",
    "db.register('reviews_annual', reviews_annual)\n",
    "\n",
    "query = '''\n",
    "       WITH listings_90 AS (\n",
    "            SELECT \n",
    "            listing_id,\n",
    "            CASE WHEN room_type = 'Entire home/apt' THEN 'Entire Home' ELSE 'Other' END AS room_type,\n",
    "            CASE WHEN est_nights_2022_2023_capped >= 90 THEN 1 ELSE 0 END AS over90_2223,\n",
    "            CASE WHEN est_nights_2022_2023_capped BETWEEN 1 AND 90 THEN 1 ELSE 0 END AS under90_2223,\n",
    "            CASE WHEN est_nights_2023_2024_capped >= 90 THEN 1 ELSE 0 END AS over90_2324,\n",
    "            CASE WHEN est_nights_2023_2024_capped BETWEEN 1 AND 90 THEN 1 ELSE 0 END AS under90_2324\n",
    "        FROM reviews_annual)\n",
    "    SELECT\n",
    "        room_type,\n",
    "        SUM(over90_2324) AS over90_2324,\n",
    "        SUM(over90_2324) + SUM(under90_2324) AS total_2324,\n",
    "        SUM(over90_2223) AS over90_2223,\n",
    "        SUM(over90_2223) + SUM(under90_2223) AS total_2223\n",
    "    FROM listings_90\n",
    "    GROUP BY 1\n",
    "'''\n",
    "\n",
    "proportions_room = db.sql(query).to_df()\n",
    "proportions_room.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9fcce583-5207-49bf-a04f-3eb9f2adb274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_type</th>\n",
       "      <th>over90_2223</th>\n",
       "      <th>total_2223</th>\n",
       "      <th>over90_2324</th>\n",
       "      <th>total_2324</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-Listing Host</td>\n",
       "      <td>5397.0</td>\n",
       "      <td>14989.0</td>\n",
       "      <td>7492.0</td>\n",
       "      <td>24225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single Property Host</td>\n",
       "      <td>3674.0</td>\n",
       "      <td>12404.0</td>\n",
       "      <td>4414.0</td>\n",
       "      <td>18109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              host_type  over90_2223  total_2223  over90_2324  total_2324\n",
       "0    Multi-Listing Host       5397.0     14989.0       7492.0     24225.0\n",
       "1  Single Property Host       3674.0     12404.0       4414.0     18109.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating final table: whether a listing had True or False for over 90 days, and aggregated by host type\n",
    "#The below calculation is not ideal as a host might have become a Superhost later\n",
    "\n",
    "#Getting number of over 90s and totals for each category, as this is what the statistical test requires\n",
    "\n",
    "query2 = '''\n",
    "       WITH host_type AS (\n",
    "       SELECT \n",
    "           host_id,\n",
    "           CASE WHEN COUNT(*)>1 THEN 'Multi-Listing Host' ELSE 'Single Property Host' END AS host_type           \n",
    "       FROM reviews_annual\n",
    "       GROUP BY 1),\n",
    "       \n",
    "       listings_90 AS (\n",
    "            SELECT \n",
    "            r.listing_id,\n",
    "            h.host_type,\n",
    "            CASE WHEN r.est_nights_2022_2023_capped >= 90 THEN 1 ELSE 0 END AS over90_2223,\n",
    "            CASE WHEN r.est_nights_2022_2023_capped BETWEEN 1 AND 90 THEN 1 ELSE 0 END AS under90_2223,\n",
    "            CASE WHEN r.est_nights_2023_2024_capped >= 90 THEN 1 ELSE 0 END AS over90_2324,\n",
    "            CASE WHEN r.est_nights_2023_2024_capped BETWEEN 1 AND 90 THEN 1 ELSE 0 END AS under90_2324,\n",
    "        FROM reviews_annual r\n",
    "            LEFT JOIN host_type h\n",
    "                ON r.host_id=h.host_id)\n",
    "        \n",
    "    SELECT\n",
    "        host_type,\n",
    "        SUM(over90_2223) AS over90_2223,\n",
    "        SUM(over90_2223) + SUM(under90_2223) AS total_2223,\n",
    "        SUM(over90_2324) AS over90_2324,\n",
    "        SUM(over90_2324) + SUM(under90_2324) AS total_2324\n",
    "    FROM listings_90\n",
    "    GROUP BY 1\n",
    "'''\n",
    "\n",
    "proportions_host = db.sql(query2).to_df()\n",
    "proportions_host.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
